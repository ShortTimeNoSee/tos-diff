We make recommendations to the people who use our services to help them discover
new communities and content. Both Facebook and Instagram may recommend content,
accounts, and entities that people do not already follow. Some examples of our
recommendation experiences include Instagram Explore, Accounts You May Like, and
the Reels tab.Our goal is to make recommendations that are relevant and valuable
to each person who sees them. We do this by personalizing recommendations, which
means making unique recommendations for each person. For example, if you
interact with restaurants and bookstores on Instagram, we may recommend content
about food, recipes, books, or reading.
<h2>
  What baseline standards does Instagram maintain for its recommendations?
</h2>
At Instagram, we have guidelines that govern what content we recommend to
people. Through those guidelines, we work to avoid making recommendations that
could be low-quality, objectionable, or sensitive, and we also avoid making
recommendations that may be inappropriate for younger viewers. Our
Recommendations Guidelines are designed to maintain a higher standard than our
Community Standards, because recommended content and connections are from
accounts you haven't chosen to follow. We use technology to detect both content
and accounts that don’t meet these Recommendations Guidelines and to help us
avoid recommending them. As always, content that goes against our
<a
  href="https://transparency.meta.com/policies/community-standards/"
  rel="nofollow noreferrer"
  target="_blank"
  >Community Standards
</a>
will be removed from Instagram.By publishing these guidelines, we want to
provide people with more information about the types of content and accounts
that we try to avoid recommending, both to keep our community more informed and
to provide guidance for content creators about recommendations.In developing
these guidelines, we sought input from 50 leading experts specializing in
recommender systems, expression, safety, and digital rights. Those consultations
are part of our constant efforts to improve these guidelines and provide people
with a safe and positive experience when they receive recommendations on our
platform.
<h2>Content Recommendations</h2>
There are four categories of content that are allowed on our platforms, but that
may not be eligible for recommendations. These categories are listed below, as
are some illustrative examples of content within each category.<b
  >Content that impedes our ability to foster a safe community, such as:</b
>
<ol>
  <li>
    Content that discusses self-harm, suicide, or eating disorders, as well as
    content that depicts or trivialises themes around death or depression. (We
    remove content that
    <a
      href="https://www.facebook.com/communitystandards/suicide_self_injury_violence"
      rel="nofollow noreferrer"
      target="_blank"
      >encourages suicide or self-injury, or any graphic imagery</a
    >.) We use technology to try to avoid showing certain types of content that
    discusses self-harm, suicide and eating disorders to people under 18 years
    old, even if they follow the account sharing it. We do allow content that
    provides support, recovery or resources on these topics for everyone.
  </li>
  <li>
    Content that may depict violence, such as people fighting. (We remove
    <a
      href="https://www.facebook.com/communitystandards/graphic_violence"
      rel="nofollow noreferrer"
      target="_blank"
      >graphically violent</a
    >
    content.) We use technology to try to avoid showing certain types of content
    that may depict violence, such as people fighting to people under 18 years
    old, even if they follow the account sharing it.
  </li>
  <li>
    Content that may be sexually explicit or suggestive, such as pictures of
    people in see-through clothing. (We remove content that contains
    <a
      href="https://www.facebook.com/communitystandards/adult_nudity_sexual_activity"
      rel="nofollow noreferrer"
      target="_blank"
      >adult nudity or sexual activity</a
    >.) We use technology to try to avoid showing sexually explicit or
    suggestive content to people under 16 years old.
  </li>
  <li>
    Content that promotes the use of certain regulated products, such as tobacco
    or vaping products, adult products and services, or pharmaceutical drugs.
    (We remove content that attempts to
    <a
      href="https://www.facebook.com/communitystandards/regulated_goods"
      rel="nofollow noreferrer"
      target="_blank"
      >sell or trade most regulated goods</a
    >.) We use technology to try to avoid showing people under 18 years old
    content that promotes non-medical drugs and marijuana even if they follow
    the account sharing it.
  </li>
  <li>Content shared by any non-recommendable account.</li>
</ol>
Note: You may be able to control how much or how little of this content you can
see on Instagram using the
<a href="https://help.instagram.com/251027992727268?helpref=faq_content">
  Sensitive Content Control</a
>. <b>Sensitive or low-quality content about Health or Finance, such as:</b>
<ol>
  <li>Content that promotes or depicts cosmetic procedures.</li>
  <li>
    Content containing exaggerated health claims, such as “miracle cures.”
  </li>
  <li>
    Content attempting to sell products or services based on health-related
    claims, such as promoting a supplement to help a person lose weight.
  </li>
  <li>
    Content that promotes misleading or deceptive business models, such as
    payday loans or “risk-free” investments.
  </li>
</ol>
<b>Content that is associated with low-quality publishing, such as:</b>
<ol>
  <li>
    Unoriginal content that is largely repurposed from another source
    <a
      href="https://about.fb.com/news/2019/04/people-publishers-the-community/"
      rel="nofollow noreferrer"
      target="_blank"
      >without adding material value</a
    >.
  </li>
  <li>
    <a
      href="https://about.fb.com/news/2019/04/remove-reduce-inform-new-steps/"
      rel="nofollow noreferrer"
      target="_blank"
      >Content from web sites that get a disproportionate number of clicks from
      Instagram versus other places on the web.</a
    >
  </li>
  <li>
    News content that does not include transparent information about authorship
    or the publisher’s editorial staff.
  </li>
</ol>
<b>False or misleading content, such as:</b>
<ol>
  <li>
    Content including claims that have been found false by independent
    fact-checkers or certain expert organizations. (We remove misinformation
    that
    <a
      href="https://www.facebook.com/communitystandards/false_news"
      rel="nofollow noreferrer"
      target="_blank"
      >could cause physical harm or suppress voting</a
    >.)
  </li>
  <li>
    <a
      href="https://about.fb.com/news/2019/03/combatting-vaccine-misinformation/"
      rel="nofollow noreferrer"
      target="_blank"
      >Vaccine-related misinformation</a
    >
    that has been widely debunked by leading global health organizations.
  </li>
  <li>
    Content that promotes the use of fraudulent documents, such as someone
    sharing a post about using a fake ID. (We remove content attempting to sell
    <a
      href="https://www.facebook.com/communitystandards/fraud_deception"
      rel="nofollow noreferrer"
      target="_blank"
      >fraudulent documents</a
    >, like medical prescriptions).
  </li>
</ol>
<h2>Account Recommendations</h2>
We also try to not recommend accounts that:
<ol>
  <li>
    Recently violated Instagram’s Community Guidelines. (This does not include
    accounts that we otherwise remove from our platforms for violating
    Instagram’s Community Guidelines.)
  </li>
  <li>Repeatedly and/or recently shared content we try not to recommend.</li>
  <li>
    Repeatedly posted
    <a
      href="https://about.fb.com/news/2019/03/combatting-vaccine-misinformation/"
      rel="nofollow noreferrer"
      target="_blank"
      >vaccine-related misinformation</a
    >
    that has been widely debunked by leading global health organizations.
  </li>
  <li>
    Repeatedly engaged in misleading practices to build followings, such as
    purchasing ‘likes’.
  </li>
  <li>Have been banned from running ads on our platforms.</li>
  <li>
    Recently and repeatedly posted false information as determined by
    independent third party fact-checkers or certain expert organizations.
  </li>
  <li>
    <a
      href="https://about.fb.com/news/2020/08/addressing-movements-and-organizations-tied-to-violence/"
      rel="nofollow noreferrer"
      target="_blank"
      >Are associated with offline movements or organizations that are tied to
      violence</a
    >.
  </li>
  <li>
    Discuss or depict suicide and self-harm in the account name, username,
    profile photo or bio (with the exception of accounts focused on providing
    support, raising awareness, and recovery).
  </li>
</ol>
A similar set of these guidelines applies to recommendations on Facebook. Those
guidelines can be found
<a
  href="https://www.facebook.com/help/1257205004624246?helpref=faq_content"
  rel="nofollow noreferrer"
  target="_blank"
  >in the Facebook Help Center.</a
>Visit the
<a
  href="https://transparency.fb.com/features/explaining-ranking"
  rel="nofollow noreferrer"
  target="_blank"
  >Meta Transparency Center</a
>
for information on how an artificial intelligence (AI) system selects, ranks and
delivers the content you see on Instagram.
